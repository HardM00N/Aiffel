{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf987db5",
   "metadata": {},
   "source": [
    "# Fund21. TF2 API\n",
    "가장 간단한 이미지 분류 문제를 풀어가면서 TF2(TensorFlow V2)를 활용한 모델링을 진행해보자.  \n",
    "TensorFlow2에서 딥러닝 모델을 작성하는 방법에는 크게 `Sequential`, `Functional`, `Module Subclassing`의 3가지가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e2505",
   "metadata": {},
   "source": [
    "### 1) Sequential Model\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32)\n",
    "```  \n",
    "\n",
    "- 입력부터 출력까지 레이어를 sequential하게 add해서 쌓아나간다. 이 방식은 초보자가 접근하기에 매우 쉽다는 것이 장점이다. \n",
    "- 모델의 입력과 출력이 여러 개인 경우에는 적합하지 않은 모델링 방식이다. Sequential 모델은 반드시 입력 1가지, 출력 1가지를 전제로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1689c80c",
   "metadata": {},
   "source": [
    "### 2) Functional API\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.fit(x,y, epochs=10, batch_size=32)\n",
    "```  \n",
    "- `Sequntial Model`을 활용하는 것과 다른 점은 `keras.Model`을 사용한다는 점이다. 이는 `Sequential Model`을 쓰는 것 보다 더 일반적인 접근이다. \n",
    "- `Functional API`를 활용하면 더 자유로운 모델링을 진행할 수 있다. 함수형으로 모델을 구성하는 것, 즉 **입력과 출력을 규정해 모델 전체를 규정**한다. \n",
    "- input이 될 수 있는 텐서가 여러 개가 될 수 있다. 레이어들을 자유롭게 엮어 출력까지 규정하면 model이 inputs와 outputs로 규정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af6f7",
   "metadata": {},
   "source": [
    "### 3) Subclassing\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.fit(x,y, epochs=10, batch_size=32)\n",
    "```\n",
    "- `Subclassing`을 활용하면 가장 자유로운 모델링을 할 수 있다. `keras.Model`을 상속 받은 모델 클래스를 만들기 때문에 `Functional`한 접근과 차이가 없다. \n",
    "- `__init__()` 메서드 안에서 레이어 구성을 정의하고, `call()` 메서드 안에서 레이어 간 forward propagation을 구현하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307fa41",
   "metadata": {},
   "source": [
    "## MNIST (1) - Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a150c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe0672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49601c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4b16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 32s 3ms/step - loss: 0.1067 - accuracy: 0.9677\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0348 - accuracy: 0.9888\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0189 - accuracy: 0.9938\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "313/313 - 1s - loss: 0.0509 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05088239535689354, 0.9860000014305115]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa017f6",
   "metadata": {},
   "source": [
    "## MNIST (2) - Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c53d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bcd1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8374ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d234910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1066 - accuracy: 0.9675\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0359 - accuracy: 0.9884\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "313/313 - 1s - loss: 0.0512 - accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.051226891577243805, 0.9865999817848206]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593b1c",
   "metadata": {},
   "source": [
    "## MNIST (3) - Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5467181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a30e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4894a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2155b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1052 - accuracy: 0.9677\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0346 - accuracy: 0.9894\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0188 - accuracy: 0.9938\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0096 - accuracy: 0.9968\n",
      "313/313 - 1s - loss: 0.0527 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052677400410175323, 0.986299991607666]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa2fe0",
   "metadata": {},
   "source": [
    "## CIFAR-100 - Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86cb4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190e75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 3s 0us/step\n",
      "169017344/169001437 [==============================] - 3s 0us/step\n",
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134997c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade5fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6051 - accuracy: 0.1592\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9178 - accuracy: 0.2803\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6087 - accuracy: 0.3440\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3882 - accuracy: 0.3894\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2146 - accuracy: 0.4278\n",
      "313/313 - 1s - loss: 2.5726 - accuracy: 0.3637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.572640895843506, 0.3637000024318695]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e3b95",
   "metadata": {},
   "source": [
    "## CIFAR-100 - Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19db7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fc1d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "537f5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6176 - accuracy: 0.1569\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9037 - accuracy: 0.2841\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6094 - accuracy: 0.3432\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4059 - accuracy: 0.3841\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2502 - accuracy: 0.4168\n",
      "313/313 - 1s - loss: 2.5962 - accuracy: 0.3591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.596174716949463, 0.35910001397132874]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4ff62",
   "metadata": {},
   "source": [
    "## CIFAR-100 - Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f42721e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deef9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88208b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2, 2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2, 2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74dd0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6635 - accuracy: 0.1481\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9801 - accuracy: 0.2667\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6933 - accuracy: 0.3219\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4845 - accuracy: 0.3694\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3188 - accuracy: 0.4020\n",
      "313/313 - 1s - loss: 2.6142 - accuracy: 0.3481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6141819953918457, 0.3481000065803528]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6eb64",
   "metadata": {},
   "source": [
    "## GrdientTape 활용\n",
    "Tensorflow에서 제공하는 `tf.GradientTape`는 forward pass로 진행된 모든 연산의 중간 레이어 값을 tape에 기록하고, 이를 이용해 gradient를 계산한 후, tape를 폐기하는 기능을 수행한다. 이전 스텝에서 진행했던 학습을 `tf.GradientTape`를 이용한 것으로 변형해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "264f0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3f0b7",
   "metadata": {},
   "source": [
    "- 아래 코드는 `tape.gradient()`를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후, `optimizer.apply_gradients()`를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 `model.trainable_variables`를 지정해주는 과정을 기술한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4e796cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # backpropagation\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d26b5e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 4.5027\n",
      "Epoch 1: last batch loss = 4.4263\n",
      "Epoch 2: last batch loss = 4.4792\n",
      "Epoch 3: last batch loss = 4.5164\n",
      "Epoch 4: last batch loss = 4.5672\n",
      "It took 71.02432513237 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70405fc",
   "metadata": {},
   "source": [
    "- `tf.GradientTape()`을 활용하면 `model.compile()`과 `model.fit()` 안에 감추어져 있던 한 스텝의 학습 단계를 끄집어내서 자유롭게 재구성할 수 있게 된다. \n",
    "- 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 `train_step` 메서드의 재구성이 필수적이므로 `tf.GradientTape()`의 활용법을 꼭 숙지하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3681237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 910ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0401"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
